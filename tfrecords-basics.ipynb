{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why TFRecords? #\n",
    "\n",
    "TPUs have eight cores which act as eight independent workers. We can get data to each core more efficiently by splitting the dataset into multiple files or **shards**. This way, each core can grab an independent part of the data as it needs.\n",
    "\n",
    "The most convenient kind of file to use for sharding in TensorFlow is a TFRecord. A TFRecord is a binary file that contains sequences of byte-strings. Data needs to be *serialized* (encoded as a byte-string) before being written into a TFRecord.\n",
    "\n",
    "The most convenient way of serializing data in TensorFlow is to wrap the data with `tf.Example`. This is a record format based on Google's protobufs but designed for TensorFlow. It's more or less like a `dict` with some type annotations.\n",
    "\n",
    "First we'll look at how to read and write data with TFRecords. Then we'll look at how to wrap data with `tf.Example`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization \n",
    "\n",
    "A TFRecord is a kind of file that TensorFlow uses to store binary data. TFRecords contain sequences of byte-strings. Here is a very simple TFRecord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "PATH = '/kaggle/working/data.tfrecord'\n",
    "\n",
    "with tf.io.TFRecordWriter(path=PATH) as f:\n",
    "    f.write(b'123') # write one record\n",
    "    f.write(b'xyz314') # write another record\n",
    "\n",
    "with open(PATH, 'rb') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TFRecord is a sequence of bytes, so we have to turn our data into byte-strings before it can go into a TFRecord. We can use `tf.io.serialize_tensor` to turn a tensor into a byte-string and `tf.io.parse_tensor` to turn it back. It's important to keep track of your tensor's datatype (in this case `tf.uint8`) since you have to specify it when parsing the string back to a tensor again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1, 2], [3, 4]], dtype=tf.uint8)\n",
    "print('x:', x, '\\n')\n",
    "\n",
    "x_bytes = tf.io.serialize_tensor(x)\n",
    "print('x_bytes:', x_bytes, '\\n')\n",
    "\n",
    "print('x:', tf.io.parse_tensor(x_bytes, out_type=tf.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data #\n",
    "\n",
    "So how do we write a dataset as a TFRecord? If your dataset is composed of byte-strings, you can use `data.TFRecordWriter`. To read it back again, use `data.TFRecordsDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset, TFRecordDataset\n",
    "from tensorflow.data.experimental import TFRecordWriter\n",
    "\n",
    "# Construct a small dataset\n",
    "ds = Dataset.from_tensor_slices([b'abc', b'123'])\n",
    "\n",
    "# Write the dataset to a TFRecord\n",
    "writer = TFRecordWriter(PATH)\n",
    "writer.write(ds)\n",
    "    \n",
    "# Read the dataset from the TFRecord\n",
    "ds_2 = TFRecordDataset(PATH)\n",
    "for x in ds_2:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataset is composed of tensors, serialize them first by mapping `tf.io.serialize_tensor` over the dataset. Then, when you read them back, map `tf.io.parse_tensor` to turn the byte-strings back into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "features = tf.constant([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6],\n",
    "], dtype=tf.uint8)\n",
    "ds = Dataset.from_tensor_slices(features)\n",
    "\n",
    "# Serialize the tensors\n",
    "ds_bytes = ds.map(tf.io.serialize_tensor)\n",
    "\n",
    "# Write a TFRecord\n",
    "writer = TFRecordWriter(PATH)\n",
    "writer.write(ds_bytes)\n",
    "\n",
    "# Read it back\n",
    "ds_bytes_2 = TFRecordDataset(PATH)\n",
    "ds_2 = ds_2.map(lambda x: tf.io.parse_tensor(x, out_type=tf.uint8))\n",
    "\n",
    "# They are the same!\n",
    "for x in ds:\n",
    "    print(x)\n",
    "print()\n",
    "for x in ds_2:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing Images ##\n",
    "\n",
    "Images can be encoded in several ways:\n",
    "- **raw** encode with `tf.io.serialize_tensor`, decode with `tf.io.parse_tensor`\n",
    "- **jpeg** encode with `tf.io.encode_jpeg`, decode with `tf.io.decode_jpeg` or `tf.io.decode_and_crop_jpeg`\n",
    "- **png** encode with `tf.io.encode_png`, decode with `tf.io.decode_png`\n",
    "\n",
    "Just be sure to use whichever decoder goes with the encoder you chose. Generally, using jpeg encoding for images is a good idea when using TPUs since this can compress the data some, potentially improving data transfer time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load numpy array\n",
    "image_raw = load_sample_image('flower.jpg')\n",
    "print(\"Type {} with dtype {}\".format(type(image_raw), image_raw.dtype))\n",
    "plt.imshow(image_raw)\n",
    "plt.title(\"Numpy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# jpeg encode / decode\n",
    "image_jpeg = tf.io.encode_jpeg(image_raw)\n",
    "print(\"Type {} with dtype {}\".format(type(image_jpeg), image_jpeg.dtype))\n",
    "print(\"Sample: {}\".format(image_jpeg.numpy()[:25]))\n",
    "Image(image_jpeg.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_raw_2 = tf.io.decode_jpeg(image_jpeg)\n",
    "\n",
    "print(\"Type {} with dtype {}\".format(type(image_raw_2), image_raw_2.dtype))\n",
    "plt.imshow(image_raw_2)\n",
    "plt.title(\"Numpy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Example #\n",
    "\n",
    "What if you have structured data, like `(image, label)` pairs? TensorFlow also includes an API for structured data, `tf.Example`. They are based on Google's [Protocol Buffers](https://developers.google.com/protocol-buffers).\n",
    "\n",
    "A single `Example` is meant to represent a single instance in a dataset, like a single `(image, label)` pair. Each `Example` has `Features`, described as a `dict` of feature names and values. A value can be either a `BytesList`, a `FloatList`, or an `Int64List`, each wrapped as a single `Feature`. There's no value type for tensors; instead, serialize tensors with `tf.io.serialize_tensor`, get the bytestring with the `numpy` method, and encode them in a `BytesList`.\n",
    "\n",
    "Here's how we could encode labeled image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "\n",
    "# The Data\n",
    "image = tf.constant([ # this could also be a numpy array\n",
    "    [0, 1, 2],\n",
    "    [3, 4, 5],\n",
    "    [6, 7, 8],\n",
    "])\n",
    "label = 0\n",
    "class_name = \"Class A\"\n",
    "\n",
    "\n",
    "# Wrap with Feature as a BytesList, FloatList, or Int64List\n",
    "image_feature = Feature(\n",
    "    bytes_list=BytesList(value=[\n",
    "        tf.io.serialize_tensor(image).numpy(),\n",
    "    ])\n",
    ")\n",
    "label_feature = Feature(\n",
    "    int64_list=Int64List(value=[label]),\n",
    ")\n",
    "class_name_feature = Feature(\n",
    "    bytes_list=BytesList(value=[\n",
    "        class_name.encode()\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "# Create a Features dictionary\n",
    "features = Features(feature={\n",
    "    'image': image_feature,\n",
    "    'label': label_feature,\n",
    "    'class_name': class_name_feature,\n",
    "})\n",
    "\n",
    "# Wrap with Example\n",
    "example = Example(features=features)\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the data is stored as attributes of the `Example` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.features.feature['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once everything is encoded as an `Example`, you can serialize it with the `SerializeToString` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_bytes = example.SerializeToString()\n",
    "print(example_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nice to wrap all this in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_example(image, label, class_name):\n",
    "    image_feature = Feature(\n",
    "        bytes_list=BytesList(value=[\n",
    "            tf.io.serialize_tensor(image).numpy(),\n",
    "        ])\n",
    "    )\n",
    "    label_feature = Feature(\n",
    "        int64_list=Int64List(value=[\n",
    "            label,\n",
    "        ])\n",
    "    )\n",
    "    class_name_feature = Feature(\n",
    "        bytes_list=BytesList(value=[\n",
    "            class_name.encode(),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    features = Features(feature={\n",
    "        'image': image_feature,\n",
    "        'label': label_feature,\n",
    "        'class_name': class_name_feature,\n",
    "    })\n",
    "    \n",
    "    example = Example(features=features)\n",
    "    \n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = make_example(\n",
    "    image=np.array([[1, 2], [3, 4]]),\n",
    "    label=1,\n",
    "    class_name=\"Class B\",\n",
    ")\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole process might look something like:\n",
    "1. Build a dataset with `tf.data.Dataset`. You could use the `from_generator` or `from_tensor_slices` methods.\n",
    "2. Serialize the dataset by iterating over the dataset with `make_example`.\n",
    "3. Write the dataset to TFRecords with `io.TFRecordWriter` or `data.TFRecordWriter`.\n",
    "\n",
    "Note, however, that to use a function like `make_example` with the `Dataset` map method you'll need to wrap it with `tf.py_function` first since TensorFlow executes dataset transformations in graph mode. You could write something like this:\n",
    "```\n",
    "ds_bytes = ds.map(lambda image, label: tf.py_function(func=make_example, inp=[image, label], Tout=tf.string))\n",
    "```\n",
    "\n",
    "See the [API docs](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) for more info.\n",
    "\n",
    "For TPU training, you'll want to shard the dataset into multiple files. the `Dataset.shard` method is handy for this, and Kaggle's [TPU documentation](https://www.kaggle.com/docs/tpu#tpu3) gives some advice about constructing shards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Serialized Examples #\n",
    "\n",
    "To decode a serialized example, we need to give TensorFlow a description of what kind of data to expect. We have just scalar entries for each so we can use `FixedLenFeature`. Pass the description to `tf.io.parse_single_example` along with the serialized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.io import FixedLenFeature, VarLenFeature\n",
    "\n",
    "feature_description = {\n",
    "    'image': FixedLenFeature([], tf.string),\n",
    "    'label': FixedLenFeature([], tf.int64),\n",
    "    'class_name': FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "example_2 = tf.io.parse_single_example(example, feature_description)\n",
    "print(\"Parsed:   \", example_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the functions from the helper script that assemble the dataset from the TFRecords. We haven't covered everything here, but hopefully it's a little more clear what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Resources #\n",
    "\n",
    "- [TPU-speed data pipelines: tf.data.Dataset and TFRecords](https://codelabs.developers.google.com/codelabs/keras-flowers-data/#4)\n",
    "- [Protocol Buffers](https://developers.google.com/protocol-buffers/)\n",
    "- [TFRecord and tf.Example](https://www.tensorflow.org/tutorials/load_data/tfrecord)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
